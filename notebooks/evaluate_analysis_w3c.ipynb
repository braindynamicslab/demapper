{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd7a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a05aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf91d0",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e0f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataset stats and results path, load in the DataFrame, merge and filter\n",
    "\n",
    "def extract_dataset(stats_path, results_path, filter_by):\n",
    "    if type(filter_by) == list:\n",
    "        assert len(filter_by) == 1, \"Can only extract 1 type of mapper\"\n",
    "        filter_by = filter_by[0]\n",
    "    stats = []\n",
    "    with open(stats_path) as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            obj = {}\n",
    "            for k,v in row.items():\n",
    "                if k == 'mapper':\n",
    "                    obj[k] = v\n",
    "                elif k.startswith('id'):\n",
    "                    pass\n",
    "                elif v == '':\n",
    "                    obj[k] = 0\n",
    "                else:\n",
    "                    obj[k] = float(v)\n",
    "            obj['SBJ'] = row['id0'] # TODO! This only works for this type of data (fix!)\n",
    "            stats.append(obj)\n",
    "    print('len(stats): ', len(stats))\n",
    "\n",
    "\n",
    "    MAX_INT = 100000\n",
    "    results = []\n",
    "    with open(results_path) as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            obj = {}\n",
    "            for k,v in row.items():\n",
    "                if k == 'Mapper' or k == 'subject':\n",
    "                    obj[k] = v\n",
    "                else:\n",
    "                    if v == 'Inf' or v == 'NaN':\n",
    "                        obj[k] = MAX_INT\n",
    "                    else:\n",
    "                        obj[k] = float(v)\n",
    "            results.append(obj)\n",
    "    print('len(results): ', len(results))\n",
    "\n",
    "    assert len(stats) == len(results)\n",
    "\n",
    "    dfs = pd.DataFrame(data=stats)\n",
    "    dfr = pd.DataFrame(data=results)\n",
    "\n",
    "    df = pd.merge(dfr, dfs,  how='left', left_on=['Mapper','subject'], right_on = ['mapper','SBJ'])\n",
    "    # df = dfr.join(dfs.set_index('Mapper'), on='Mapper')\n",
    "    \n",
    "    # Use filter_by\n",
    "    df = df[df['Mapper'].str.startswith(filter_by)]\n",
    "\n",
    "    param_cols = None\n",
    "    if filter_by == 'BDLMapper' or filter_by == 'NeuMapper':\n",
    "        df['K'] = df.apply(lambda x: int(x['Mapper'].split('_')[1]), axis=1)\n",
    "        df['R'] = df.apply(lambda x: int(x['Mapper'].split('_')[2]), axis=1)\n",
    "        df['G'] = df.apply(lambda x: int(x['Mapper'].split('_')[3]), axis=1)\n",
    "        param_cols = ['K', 'R', 'G']\n",
    "    elif filter_by == 'CustomBDLMapper' or filter_by == 'CustomNeuMapper':\n",
    "        df['preptype'] = df.apply(lambda x: x['Mapper'].split('_')[1], axis=1)\n",
    "        df['dist'] = df.apply(lambda x: x['Mapper'].split('_')[2], axis=1)\n",
    "        df['K'] = df.apply(lambda x: int(x['Mapper'].split('_')[3]), axis=1)\n",
    "        df['R'] = df.apply(lambda x: int(x['Mapper'].split('_')[4]), axis=1)\n",
    "        df['G'] = df.apply(lambda x: int(x['Mapper'].split('_')[5]), axis=1)\n",
    "        df['linkbins'] = df.apply(lambda x: int(x['Mapper'].split('_')[6]), axis=1)\n",
    "        param_cols = ['preptype', 'dist', 'K', 'R', 'G', 'linkbins']\n",
    "    elif filter_by == 'CMDSMapperNoKNN':\n",
    "        df['preptype'] = df.apply(lambda x: x['Mapper'].split('_')[1], axis=1)\n",
    "        df['dist'] = df.apply(lambda x: x['Mapper'].split('_')[2], axis=1)\n",
    "        df['R'] = df.apply(lambda x: int(x['Mapper'].split('_')[3]), axis=1)\n",
    "        df['G'] = df.apply(lambda x: int(x['Mapper'].split('_')[4]), axis=1)\n",
    "        df['linkbins'] = df.apply(lambda x: int(x['Mapper'].split('_')[5]), axis=1)\n",
    "        param_cols = ['preptype', 'dist', 'R', 'G', 'linkbins']\n",
    "    else:\n",
    "        raise Exception('Mapper type not recognized')\n",
    "        \n",
    "\n",
    "    # fix CircleLoss and TransitionBetweeness\n",
    "    max_values = {}\n",
    "    for colname in [\"CircleLoss\", \"TransitionBetweeness\"]:\n",
    "        if len(df[df[colname] < MAX_INT][colname]) == 0:\n",
    "            raise Exception('There are no valid values for {}'.format(colname))\n",
    "        new_max_loss = max(df[df[colname] < MAX_INT][colname]) * 1.5\n",
    "        max_values[colname] = new_max_loss\n",
    "        df[colname] = df.apply(lambda x: x[colname] if x[colname] != MAX_INT else new_max_loss, axis=1)\n",
    "\n",
    "    main_cols = ['Mapper', 'SBJ'] + param_cols\n",
    "    other_cols = [c for c in df.columns.tolist() if c not in main_cols and c != 'Mapper' and c != 'subject']\n",
    "    df = df[main_cols + other_cols]\n",
    "        \n",
    "    return df, max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99616629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the subjects for each datset type and the combination that we should compute.\n",
    "# for example: all SBJ2* would be SBJ20 and SBJ21\n",
    "# For new datasets, this has to be changed\n",
    "\n",
    "def get_all_parameters(df, dataset_name, silent=False):\n",
    "    all_sbjs = df['SBJ'].unique().tolist()\n",
    "    if not silent:\n",
    "        print('Total {} subjects:'.format(len(all_sbjs)))\n",
    "        for sbj in all_sbjs:\n",
    "            print(sbj)\n",
    "\n",
    "\n",
    "    sbjs_map = {}\n",
    "\n",
    "    if dataset_name.startswith('ss_'):\n",
    "        # This is for subsampled data\n",
    "        for sbj in all_sbjs:\n",
    "            sbjs_map[sbj] = [sbj]\n",
    "\n",
    "        sbjs_map['SBJ2x'] = ['SBJ20', 'SBJ21']\n",
    "        sbjs_map['SBJ4x'] = ['SBJ40', 'SBJ41', 'SBJ42', 'SBJ43']\n",
    "        sbjs_map['SBJxx-50'] = [sbj for sbj in all_sbjs if sbj.endswith('-50.0')]\n",
    "        sbjs_map['SBJxx-75'] = [sbj for sbj in all_sbjs if sbj.endswith('-75.0')]\n",
    "        sbjs_map['SBJxx-83'] = [sbj for sbj in all_sbjs if sbj.endswith('-83.0')]\n",
    "        sbjs_map['SBJxx-99'] = ['SBJ20', 'SBJ40', 'SBJ99']\n",
    "\n",
    "    elif dataset_name.startswith('wnoise_'):\n",
    "        # This is for wnoise data\n",
    "        for sbj in all_sbjs:\n",
    "            sbjs_map[sbj] = [sbj]\n",
    "\n",
    "    elif dataset_name.startswith('hightr_'):\n",
    "        # This is for subsampled data hightr\n",
    "        for sbj in all_sbjs:\n",
    "            sbjs_map[sbj] = [sbj]\n",
    "\n",
    "        for i in [2,3,4]:\n",
    "            sbjs_map['SBJe{}'.format(i)] = [s for s in all_sbjs if 'e{}v'.format(i) in s]\n",
    "\n",
    "    if not silent:\n",
    "        print('Extra combinations:')\n",
    "        for sbjname, sbjs_list in sbjs_map.items():\n",
    "            if len(sbjs_list) > 1:\n",
    "                print(sbjname, ':', sbjs_list)\n",
    "            \n",
    "    return all_sbjs, sbjs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063aa225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm, Normalize\n",
    "\n",
    "def _handle_list_cols(df, col):\n",
    "    if type(col) == list:\n",
    "        newcol = '_'.join(col)\n",
    "        df[newcol] = df.apply(lambda x: '_'.join([str(x[c]) for c in col]), axis=1)\n",
    "        col = newcol\n",
    "    return df, col\n",
    "    \n",
    "\n",
    "# For a DataFrame, compute a big figure with multiple subplots\n",
    "# Each row would be a different metric (some metrics are in log scale `log_metrics`)\n",
    "# Each column is a different value of the fixedV column (usually `R`)\n",
    "# For each subplot, x-axis is colV column (usually `G`) and y-axis is indexV column (usually `K`)\n",
    "# The `sbj_group_name` is the name of the group of subjects\n",
    "def plot_results(df, sbj_group_name, sbj_group, fixedV, indexV, colV, target_metrics, log_metrics, resdir):\n",
    "    df, fixedV = _handle_list_cols(df, fixedV)\n",
    "    df, indexV = _handle_list_cols(df, indexV)\n",
    "    df, colV = _handle_list_cols(df, colV)\n",
    "    \n",
    "    df_filter = df['SBJ'] == sbj_group[0]\n",
    "    for idx in range(1,len(sbj_group)):\n",
    "        df_filter = df_filter | (df['SBJ'] == sbj_group[idx])\n",
    "    \n",
    "    newtypes = {}\n",
    "    allcols = []\n",
    "    for col in [fixedV, indexV, colV]:\n",
    "        col = col if type(col) == list else [col]\n",
    "        allcols.extend(col)\n",
    "        for c in col:\n",
    "            if c in ['K', 'G', 'R', 'linkbins']:\n",
    "                newtypes[c] = 'int'\n",
    "                \n",
    "    # Filter and group by subject/subjects\n",
    "    dff = df[df_filter]\n",
    "    dff = dff.groupby(['Mapper'] + allcols).mean()\n",
    "    dff = dff.reset_index().astype(newtypes)\n",
    "    # Deprecated below\n",
    "    # Don't recompute CircleLossRev as next line, average over the CircleLossRev!\n",
    "    # dff['CircleLossRev'] = dff.apply(lambda x: 1.0 / x['CircleLoss'] if x['CircleLoss'] > 0 else 100, axis=1)\n",
    "\n",
    "    fixed_vals = sorted(list(set(df[fixedV].to_list())))\n",
    "    f, axr = plt.subplots(len(target_metrics), len(fixed_vals), figsize=(4 * len(fixed_vals), 4 * len(target_metrics)))\n",
    "\n",
    "    for axc, target in zip(axr, target_metrics):\n",
    "        vmin, vmax = min(df[target]), max(df[target]) # get vmin and vmax based on all results not only for the sbj group\n",
    "        for col_idx,(K,ax) in enumerate(zip(fixed_vals,axc)):\n",
    "            df_p = dff[dff[fixedV] == K].pivot(index=indexV, columns=colV, values=target)\n",
    "            \n",
    "            last_col = col_idx == len(axc) - 1\n",
    "            if target in log_metrics:\n",
    "                ax = sns.heatmap(df_p, norm=LogNorm(vmin=vmin, vmax=vmax), ax=ax, cbar=not last_col)\n",
    "            else:\n",
    "                ax = sns.heatmap(df_p, vmin=vmin, vmax=vmax, ax=ax, cbar=not last_col)\n",
    "            ax.set_title('{} == {}'.format(fixedV, K))\n",
    "\n",
    "            if last_col:\n",
    "                ax1 = ax.twinx()\n",
    "                ax1.set_ylabel(target)\n",
    "                ax1.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(resdir,'plot_results_{}.png'.format(sbj_group_name)))\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "# Similar to `plot_results`, this function has a map of target_metrics to an interval.\n",
    "# If the picked metric inside the interval, then the value is 1, otherwise its 0\n",
    "# This figure also has a row of TOTAL where all metrics are combined to yield the combination of \"AND\" on all metrics\n",
    "def plot_limits(df, sbj_group_name, sbj_group, fixedV, indexV, colV, target_metrics, resdir):\n",
    "    df, fixedV = _handle_list_cols(df, fixedV)\n",
    "    df, indexV = _handle_list_cols(df, indexV)\n",
    "    df, colV = _handle_list_cols(df, colV)\n",
    "\n",
    "    newtypes = {}\n",
    "    allcols = []\n",
    "    for col in [fixedV, indexV, colV]:\n",
    "        col = col if type(col) == list else [col]\n",
    "        allcols.extend(col)\n",
    "        for c in col:\n",
    "            if c in ['K', 'G', 'R', 'linkbins']:\n",
    "                newtypes[c] = 'int'\n",
    "    \n",
    "    df_filter = df['SBJ'] == sbj_group[0]\n",
    "    for idx in range(1,len(sbj_group)):\n",
    "        df_filter = df_filter | (df['SBJ'] == sbj_group[idx])\n",
    "    \n",
    "    dff = df[df_filter]\n",
    "    dff = dff.groupby(['Mapper'] + allcols).mean()\n",
    "    dff = dff.reset_index().astype(newtypes)\n",
    "\n",
    "    fixed_vals = sorted(list(set(df[fixedV].to_list())))\n",
    "    f, axr = plt.subplots(len(target_metrics)+1, len(fixed_vals), figsize=(4 * len(fixed_vals), 4 * len(target_metrics) + 4))\n",
    "    \n",
    "    for axc, (target, lims) in zip(axr, target_metrics.items()):\n",
    "        vmin, vmax = min(df[target]), max(df[target]) # get vmin and vmax based on all results not only for the sbj group\n",
    "        for col_idx,(K,ax) in enumerate(zip(fixed_vals,axc)):\n",
    "            df_p = dff[dff[fixedV] == K].pivot(index=indexV, columns=colV, values=target)\n",
    "            df_wl = (df_p >= lims[0]) & (df_p <= lims[1]) # within limits\n",
    "            \n",
    "            last_col = col_idx == len(axc)-1\n",
    "            ax = sns.heatmap(df_wl, vmin=0.0, vmax=1.0, ax=ax, cbar=not last_col)\n",
    "            ax.set_title('{} == {}'.format(fixedV, K))\n",
    "            if last_col:\n",
    "                ax1 = ax.twinx()\n",
    "                ax1.set_ylabel(target)\n",
    "                ax1.set_yticks([])\n",
    "                \n",
    "    \n",
    "    # plot the combined plot\n",
    "    axc = axr[len(target_metrics)]\n",
    "\n",
    "    for col_idx,(K,ax) in enumerate(zip(fixed_vals,axc)):\n",
    "        comb_isset = False\n",
    "        df_comb = None\n",
    "        for target, lims in target_metrics.items():\n",
    "            df_p = dff[dff[fixedV] == K].pivot(index=indexV, columns=colV, values=target)\n",
    "            df_wl = (df_p >= lims[0]) & (df_p <= lims[1]) # within limits\n",
    "            if not comb_isset:\n",
    "                df_comb = df_wl\n",
    "                comb_isset = True\n",
    "            else:\n",
    "                df_comb = df_comb & df_wl\n",
    "\n",
    "        last_col = col_idx == len(axc)-1\n",
    "        ax = sns.heatmap(df_comb, vmin=0.0, vmax=1.0, ax=ax, cbar=not last_col)\n",
    "        ax.set_title('{} == {}'.format(fixedV, K))\n",
    "\n",
    "        if last_col:\n",
    "            ax1 = ax.twinx()\n",
    "            ax1.set_ylabel('TOTAL')\n",
    "            ax1.set_yticks([])\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(resdir,'plot_limits_{}.png'.format(sbj_group_name)))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31775b7a",
   "metadata": {},
   "source": [
    "# Analysis of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1961273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "\n",
    "DATASETS = {\n",
    "    'ss_w3cv1': '/Users/dh/workspace/BDL/demapper/results/w3c_ss/analysis/mappers_w3cv1.json/',\n",
    "    'ss_w3cv2': '/Users/dh/workspace/BDL/demapper/results/w3c_ss/analysis/mappers_w3cv2.json/',\n",
    "    'ss_w3cv3': '/Users/dh/workspace/BDL/demapper/results/w3c_ss/analysis/mappers_w3cv3.json/',\n",
    "    'ss_w3cv4': '/Users/dh/workspace/BDL/demapper/results/w3c_ss/analysis/mappers_w3cv4.json/',\n",
    "    'ss_w3cv5': '/Users/dh/workspace/BDL/demapper/results/w3c_ss/analysis/mappers_w3cv5fixed.json/',\n",
    "    'ss_w3cv6': '/Users/dh/workspace/BDL/demapper/results/w3c_ss/analysis/mappers_w3cv6fixed.json/',\n",
    "    'wnoise_w3cv1': '/Users/dh/workspace/BDL/demapper/results/w3c_wnoise/analysis/mappers_w3cv1.json/',\n",
    "    'wnoise_w3cv2': '/Users/dh/workspace/BDL/demapper/results/w3c_wnoise/analysis/mappers_w3cv2.json/',\n",
    "    'wnoise_w3cv4': '/Users/dh/workspace/BDL/demapper/results/w3c_wnoise/analysis/mappers_w3cv4.json/',\n",
    "    'wnoise_w3cv5': '/Users/dh/workspace/BDL/demapper/results/w3c_wnoise/analysis/mappers_w3cv5dist.json/',\n",
    "    'wnoise_w3cv6': '/Users/dh/workspace/BDL/demapper/results/w3c_wnoise/analysis/mappers_w3cv6dist.json/',\n",
    "    'hightr_w3cv1': '/Users/dh/workspace/BDL/demapper/results/w3c_hightr/analysis/mappers_w3cv1.json/',\n",
    "    'hightr_w3cv2': '/Users/dh/workspace/BDL/demapper/results/w3c_hightr/analysis/mappers_w3cv2.json/',\n",
    "    'hightr_w3cv3': '/Users/dh/workspace/BDL/demapper/results/w3c_hightr/analysis/mappers_w3cv3.json/',\n",
    "    'hightr_w3cv4': '/Users/dh/workspace/BDL/demapper/results/w3c_hightr/analysis/mappers_w3cv4.json/',\n",
    "    'hightr_w3cv5': '/Users/dh/workspace/BDL/demapper/results/w3c_hightr/analysis/mappers_w3cv5dist.json/',\n",
    "    'hightr_w3cv6': '/Users/dh/workspace/BDL/demapper/results/w3c_hightr/analysis/mappers_w3cv6dist.json/',\n",
    "}\n",
    "\n",
    "FILTERS = {}\n",
    "for k in DATASETS.keys():\n",
    "    if k.endswith('w3cv1') or k.endswith('w3cv3'):\n",
    "        FILTERS[k] = ['BDLMapper']\n",
    "    elif k.endswith('w3cv2') or k.endswith('w3cv4'):\n",
    "        FILTERS[k] = ['NeuMapper']\n",
    "    if k.endswith('w3cv5'):\n",
    "        FILTERS[k] = ['CustomBDLMapper', 'CMDSMapperNoKNN']\n",
    "    if k.endswith('w3cv6'):\n",
    "        FILTERS[k] = ['CustomNeuMapper']\n",
    "\n",
    "def get_plot_columns(mapper_name):\n",
    "    if mapper_name == 'NeuMapper' or mapper_name == 'BDLMapper':\n",
    "        fixedV, indexV, colV = 'R', 'K', 'G' # Most informative\n",
    "    elif mapper_name == 'CustomBDLMapper' or mapper_name == 'CustomNeuMapper':\n",
    "        fixedV, indexV, colV = 'dist', ['G', 'K'], ['preptype', 'R', 'linkbins']\n",
    "    elif mapper_name == 'CMDSMapperNoKNN':\n",
    "        fixedV, indexV, colV = 'dist', ['G', 'linkbins'], ['preptype', 'R']\n",
    "    else:\n",
    "        raise Exception('Cannot find plot vars (for columns) for Mapper {}'.format(mapper_name))\n",
    "    return fixedV, indexV, colV\n",
    "        \n",
    "circle_loss_threshold = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f5fed7",
   "metadata": {},
   "source": [
    "### Run for one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "035c7421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(stats):  7560\n",
      "len(results):  7560\n",
      "Total 14 subjects:\n",
      "SBJ20\n",
      "SBJ20-50.0\n",
      "SBJ20-75.0\n",
      "SBJ20-83.0\n",
      "SBJ21\n",
      "SBJ40\n",
      "SBJ40-50.0\n",
      "SBJ40-75.0\n",
      "SBJ40-83.0\n",
      "SBJ41\n",
      "SBJ99\n",
      "SBJ99-50.0\n",
      "SBJ99-75.0\n",
      "SBJ99-83.0\n",
      "Extra combinations:\n",
      "SBJ2x : ['SBJ20', 'SBJ21']\n",
      "SBJ4x : ['SBJ40', 'SBJ41', 'SBJ42', 'SBJ43']\n",
      "SBJxx-50 : ['SBJ20-50.0', 'SBJ40-50.0', 'SBJ99-50.0']\n",
      "SBJxx-75 : ['SBJ20-75.0', 'SBJ40-75.0', 'SBJ99-75.0']\n",
      "SBJxx-83 : ['SBJ20-83.0', 'SBJ40-83.0', 'SBJ99-83.0']\n",
      "SBJxx-99 : ['SBJ20', 'SBJ40', 'SBJ99']\n",
      "{'CircleLoss': 54.02777777777774, 'TransitionBetweeness': 21.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mapper</th>\n",
       "      <th>SBJ</th>\n",
       "      <th>preptype</th>\n",
       "      <th>dist</th>\n",
       "      <th>K</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>linkbins</th>\n",
       "      <th>CircleLoss</th>\n",
       "      <th>TransitionBetweeness</th>\n",
       "      <th>mapper</th>\n",
       "      <th>coverage_nodes</th>\n",
       "      <th>coverage_TRs</th>\n",
       "      <th>hrfdur_stat</th>\n",
       "      <th>distances_max</th>\n",
       "      <th>distances_entropy</th>\n",
       "      <th>assortativity</th>\n",
       "      <th>degree_TRs_avg</th>\n",
       "      <th>degree_TRs_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>CustomNeuMapper_none_correlation_16_300_35_10</td>\n",
       "      <td>SBJ40-50.0</td>\n",
       "      <td>none</td>\n",
       "      <td>correlation</td>\n",
       "      <td>16</td>\n",
       "      <td>300</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>54.027778</td>\n",
       "      <td>21.0</td>\n",
       "      <td>CustomNeuMapper_none_correlation_16_300_35_10</td>\n",
       "      <td>0.117470</td>\n",
       "      <td>0.278511</td>\n",
       "      <td>0.228916</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.09944</td>\n",
       "      <td>0.043488</td>\n",
       "      <td>16.7287</td>\n",
       "      <td>4.77802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>CustomNeuMapper_PCA_chebychev_16_300_50_10</td>\n",
       "      <td>SBJ99-75.0</td>\n",
       "      <td>PCA</td>\n",
       "      <td>chebychev</td>\n",
       "      <td>16</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>7.854839</td>\n",
       "      <td>21.0</td>\n",
       "      <td>CustomNeuMapper_PCA_chebychev_16_300_50_10</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.804217</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.57250</td>\n",
       "      <td>0.384195</td>\n",
       "      <td>883.8810</td>\n",
       "      <td>9.51419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>CustomNeuMapper_PCA_euclidean_48_200_65_10</td>\n",
       "      <td>SBJ99-75.0</td>\n",
       "      <td>PCA</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>48</td>\n",
       "      <td>200</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>0.180754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CustomNeuMapper_PCA_euclidean_48_200_65_10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.32758</td>\n",
       "      <td>0.309257</td>\n",
       "      <td>2344.6900</td>\n",
       "      <td>9.70227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6564</th>\n",
       "      <td>CustomNeuMapper_none_cosine_48_100_35_10</td>\n",
       "      <td>SBJ99-75.0</td>\n",
       "      <td>none</td>\n",
       "      <td>cosine</td>\n",
       "      <td>48</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>54.027778</td>\n",
       "      <td>21.0</td>\n",
       "      <td>CustomNeuMapper_none_cosine_48_100_35_10</td>\n",
       "      <td>0.575472</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.613208</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.46891</td>\n",
       "      <td>0.013214</td>\n",
       "      <td>225.3310</td>\n",
       "      <td>7.29296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>CustomNeuMapper_PCA_cosine_32_300_50_20</td>\n",
       "      <td>SBJ20</td>\n",
       "      <td>PCA</td>\n",
       "      <td>cosine</td>\n",
       "      <td>32</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>54.027778</td>\n",
       "      <td>21.0</td>\n",
       "      <td>CustomNeuMapper_PCA_cosine_32_300_50_20</td>\n",
       "      <td>0.626404</td>\n",
       "      <td>0.552490</td>\n",
       "      <td>0.522472</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.96522</td>\n",
       "      <td>0.477861</td>\n",
       "      <td>825.6520</td>\n",
       "      <td>9.18380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Mapper         SBJ preptype  \\\n",
       "5466  CustomNeuMapper_none_correlation_16_300_35_10  SBJ40-50.0     none   \n",
       "208      CustomNeuMapper_PCA_chebychev_16_300_50_10  SBJ99-75.0      PCA   \n",
       "3680     CustomNeuMapper_PCA_euclidean_48_200_65_10  SBJ99-75.0      PCA   \n",
       "6564       CustomNeuMapper_none_cosine_48_100_35_10  SBJ99-75.0     none   \n",
       "2730        CustomNeuMapper_PCA_cosine_32_300_50_20       SBJ20      PCA   \n",
       "\n",
       "             dist   K    R   G  linkbins  CircleLoss  TransitionBetweeness  \\\n",
       "5466  correlation  16  300  35        10   54.027778                  21.0   \n",
       "208     chebychev  16  300  50        10    7.854839                  21.0   \n",
       "3680    euclidean  48  200  65        10    0.180754                   0.0   \n",
       "6564       cosine  48  100  35        10   54.027778                  21.0   \n",
       "2730       cosine  32  300  50        20   54.027778                  21.0   \n",
       "\n",
       "                                             mapper  coverage_nodes  \\\n",
       "5466  CustomNeuMapper_none_correlation_16_300_35_10        0.117470   \n",
       "208      CustomNeuMapper_PCA_chebychev_16_300_50_10        0.993976   \n",
       "3680     CustomNeuMapper_PCA_euclidean_48_200_65_10        1.000000   \n",
       "6564       CustomNeuMapper_none_cosine_48_100_35_10        0.575472   \n",
       "2730        CustomNeuMapper_PCA_cosine_32_300_50_20        0.626404   \n",
       "\n",
       "      coverage_TRs  hrfdur_stat  distances_max  distances_entropy  \\\n",
       "5466      0.278511     0.228916           11.0            3.09944   \n",
       "208       0.998400     0.804217           16.0            3.57250   \n",
       "3680      1.000000     0.909910            6.0            2.32758   \n",
       "6564      0.505600     0.613208           21.0            3.46891   \n",
       "2730      0.552490     0.522472           26.0            3.96522   \n",
       "\n",
       "      assortativity  degree_TRs_avg  degree_TRs_entropy  \n",
       "5466       0.043488         16.7287             4.77802  \n",
       "208        0.384195        883.8810             9.51419  \n",
       "3680       0.309257       2344.6900             9.70227  \n",
       "6564       0.013214        225.3310             7.29296  \n",
       "2730       0.477861        825.6520             9.18380  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PICKED_DATASET = 'ss_w3cv6'\n",
    "\n",
    "datadir = DATASETS[PICKED_DATASET]\n",
    "stats_path = os.path.join(datadir, 'compute_stats-combined.csv')\n",
    "results_path = os.path.join(datadir, 'scores-all.csv')\n",
    "\n",
    "filter_by = FILTERS[PICKED_DATASET][0]\n",
    "df, max_values = extract_dataset(stats_path, results_path, filter_by)\n",
    "\n",
    "resdir = datadir\n",
    "if len(FILTERS[PICKED_DATASET]) > 1:\n",
    "    resdir = os.path.join(datadir, filter_by)\n",
    "    os.makedirs(resdir, exist_ok=True)\n",
    "\n",
    "\n",
    "all_sbjs, sbjs_map = get_all_parameters(df, PICKED_DATASET)\n",
    "\n",
    "print(max_values)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19fc4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85121ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69faee00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [03:32<00:00, 10.62s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_metrics = ['CircleLossRev', 'TransitionBetweenessRev', 'coverage_nodes', 'hrfdur_stat', 'distances_entropy']\n",
    "log_metrics = ['CircleLossRev', 'TransitionBetweenessRev']\n",
    "\n",
    "df['CircleLossRev'] = df.apply(lambda x: 1.0 / x['CircleLoss'] if x['CircleLoss'] > 0 else 100, axis=1)\n",
    "df['TransitionBetweenessRev'] = df.apply(lambda x: 1.0 / (x['TransitionBetweeness'] + 1), axis=1)\n",
    "\n",
    "\n",
    "for sbj_group_name, sbj_group in tqdm(sbjs_map.items()):\n",
    "    plot_results(df, sbj_group_name, sbj_group, fixedV, indexV, colV, target_metrics, log_metrics, resdir=resdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0d83b78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [03:01<00:00,  9.10s/it]\n"
     ]
    }
   ],
   "source": [
    "# Plot limits\n",
    "\n",
    "target_metrics = {\n",
    "    'CircleLoss': [0, circle_loss_threshold],\n",
    "    'TransitionBetweeness': [0, max_values['TransitionBetweeness'] * 0.99],\n",
    "    'coverage_nodes': [0.7, 1.0],\n",
    "#     'hrfdur_stat': [0.15, 1.0],\n",
    "    'distances_entropy': [2.0, 10000.0]\n",
    "}\n",
    "\n",
    "fixedV, indexV, colV = get_plot_columns(filter_by)\n",
    "\n",
    "for sbj_group_name, sbj_group in tqdm(sbjs_map.items()):\n",
    "    plot_limits(df, sbj_group_name, sbj_group, fixedV, indexV, colV, target_metrics, resdir=resdir)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5b970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9b62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9b9c559",
   "metadata": {},
   "source": [
    "## Recompute for all analysis that we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57260662",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Processing wnoise_w3cv4\n",
      "len(stats):  4200\n",
      "len(results):  4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "plot_limits: 100%|███████████████████████████████████████████████████████████████████████| 6/6 [00:51<00:00,  8.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Processing wnoise_w3cv5\n",
      "len(stats):  4320\n",
      "len(results):  4320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "plot_limits: 100%|███████████████████████████████████████████████████████████████████████| 6/6 [00:33<00:00,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(stats):  4320\n",
      "len(results):  4320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "plot_limits: 100%|███████████████████████████████████████████████████████████████████████| 6/6 [00:25<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Processing wnoise_w3cv6\n",
      "len(stats):  3240\n",
      "len(results):  3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "plot_limits: 100%|███████████████████████████████████████████████████████████████████████| 6/6 [00:34<00:00,  5.83s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_metrics = ['CircleLossRev', 'TransitionBetweenessRev', 'coverage_nodes', 'hrfdur_stat', 'distances_entropy']\n",
    "log_metrics = ['CircleLossRev', 'TransitionBetweenessRev']\n",
    "\n",
    "circle_loss_threshold = 2.0\n",
    "\n",
    "target_metrics_limits = {\n",
    "#     'CircleLoss': [0, circle_loss_threshold],\n",
    "#     'TransitionBetweeness': [0, max_values['TransitionBetweeness'] * 0.99], # Need the data first, add later\n",
    "    'coverage_nodes': [0.7, 1.0],\n",
    "    'distances_entropy': [2.0, 10000.0]\n",
    "}\n",
    "\n",
    "#     'hrfdur_stat': [0.15, 1.0], # SKip using hrfdurstat since it doesn't have an impact at >= 15%\n",
    "\n",
    "# hightr_w3cv2  ss_w3cv5\n",
    "\n",
    "for dataset_name in DATASETS.keys():\n",
    "    if dataset_name not in ['wnoise_w3cv4', 'wnoise_w3cv5', 'wnoise_w3cv6']:\n",
    "        continue\n",
    "    print('======= Processing', dataset_name)\n",
    "    datadir = DATASETS[dataset_name]\n",
    "    stats_path = os.path.join(datadir, 'compute_stats-combined.csv')\n",
    "    results_path = os.path.join(datadir, 'scores-all.csv')\n",
    "\n",
    "    try:\n",
    "        for filter_by in FILTERS[dataset_name]:\n",
    "            resdir = datadir\n",
    "            if len(FILTERS[dataset_name]) > 1:\n",
    "                resdir = os.path.join(datadir, filter_by)\n",
    "                os.makedirs(resdir, exist_ok=True)\n",
    "            df, max_values = extract_dataset(stats_path, results_path, filter_by)\n",
    "            all_sbjs, sbjs_map = get_all_parameters(df, dataset_name, silent=True)\n",
    "\n",
    "            fixedV, indexV, colV = get_plot_columns(filter_by)\n",
    "\n",
    "            df['CircleLossRev'] = df.apply(lambda x: 1.0 / x['CircleLoss'] if x['CircleLoss'] > 0 else 100, axis=1)\n",
    "            df['TransitionBetweenessRev'] = df.apply(lambda x: 1.0 / (x['TransitionBetweeness'] + 1), axis=1)    \n",
    "#             for sbj_group_name, sbj_group in tqdm(sbjs_map.items(), desc='plot_results'):\n",
    "#                 plot_results(df, sbj_group_name, sbj_group, fixedV, indexV, colV, target_metrics, log_metrics, resdir=resdir)\n",
    "\n",
    "            target_metrics_limits['TransitionBetweeness'] = [0.0, max_values['TransitionBetweeness'] * 0.99]\n",
    "            for sbj_group_name, sbj_group in tqdm(sbjs_map.items(), desc='plot_limits'):\n",
    "                plot_limits(df, sbj_group_name, sbj_group, fixedV, indexV, colV, target_metrics_limits, resdir=resdir)\n",
    "    except Exception as err:\n",
    "        print(\"Warning! Didn't process '{}' because:\".format(dataset_name))\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4564017-99fa-45f2-b599-5dc6dee7fe16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0fb81-62e9-47a6-8e53-42dcd6568451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bfe935-d65c-42b4-82b9-e05706ba55d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1edffc0-acad-42e0-b72e-862deaf739cc",
   "metadata": {},
   "source": [
    "### Other plots (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485df04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_plot(df, ax, hparam, target, title=None):\n",
    "    labels = sorted(list(df[hparam].unique()))\n",
    "    data = [df[df[hparam] == label][target] for label in labels]\n",
    "    ax = sns.boxplot(data=data, ax=ax)\n",
    "    ax = sns.swarmplot(data=data, color=\".25\", ax=ax, size=1.5)\n",
    "    ax.set_xticklabels(labels, rotation=10)\n",
    "    ax.set_xlabel(hparam)\n",
    "    ax.set_ylabel(target)\n",
    "    ax.set_title('Distribution of {} over {}'.format(target,hparam) if not title else title)\n",
    "    ax.grid(alpha=0.4)\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'ChangePointsIndicesError'\n",
    "\n",
    "plt.figure()\n",
    "ax = create_plot(df, None, 'K', target)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax = create_plot(df, None, 'R', target)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax = create_plot(df, None, 'G', target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba755c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'ChangePointsResiduals'\n",
    "plt.figure()\n",
    "ax = create_plot(df, None, 'K', target)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax = create_plot(df, None, 'R', target)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax = create_plot(df, None, 'G', target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e004f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_trisurf(df['R'], df['G'], df['K'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2102be1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot of indices error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04cf5be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef8bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec6010-eee1-443d-affd-4eb35d8da2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f31e10-371a-435f-b602-d295e7780b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df[df['R'] == 300]['hrfdur_stat-mean'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ed21e-36d1-4ba1-852f-ffcd9519c22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17613785-eb76-4c3e-8357-7275c73eb762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493bbbda-d570-41a3-a5bb-9b54c2148aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a10a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
